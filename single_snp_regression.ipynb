{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the csv: 4\n",
      "Current column: 3\n",
      "a\n",
      "a\n",
      "the_col is: \n",
      "[(8,)]\n",
      "p_col\n",
      "Tensor(\"stack_34:0\", shape=(1, 1), dtype=int32)\n",
      "the mean is: \n",
      "8\n",
      "Current column: 1\n",
      "a\n",
      "a\n",
      "the_col is: \n",
      "[(6,)]\n",
      "p_col\n",
      "Tensor(\"stack_35:0\", shape=(1, 1), dtype=int32)\n",
      "the mean is: \n",
      "6\n",
      "Current column: 0\n",
      "a\n",
      "a\n",
      "the_col is: \n",
      "[(5,)]\n",
      "p_col\n",
      "Tensor(\"stack_36:0\", shape=(1, 1), dtype=int32)\n",
      "the mean is: \n",
      "5\n",
      "Current column: 2\n",
      "a\n",
      "a\n",
      "the_col is: \n",
      "[(7,)]\n",
      "p_col\n",
      "Tensor(\"stack_37:0\", shape=(1, 1), dtype=int32)\n",
      "the mean is: \n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# WORKING VERSION\n",
    "\n",
    "from random import shuffle\n",
    "#import tensorflow as tf\n",
    "\n",
    "# Get the numbers of columns in the csv:\n",
    "\n",
    "csv_in = open(\"ex.csv\", \"r\")                        # open the csv\n",
    "ncol = len(csv_in.readline().split(\",\"))            # read the first line and count the # of columns\n",
    "csv_in.close()                                      # close the csv\n",
    "print(\"Number of columns in the csv: \" + str(ncol)) # print the # of columns\n",
    "\n",
    "# Create a random column reading list:\n",
    "col_list = list(range(ncol))\n",
    "shuffle(col_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for i in col_list:\n",
    "        dataset = tf.contrib.data.CsvDataset(\n",
    "            \"ex.csv\",\n",
    "            [tf.int32],\n",
    "            select_cols=[i]  # Only parse last three columns\n",
    "        )\n",
    "        next_element = dataset.make_one_shot_iterator().get_next()\n",
    "        print('Current column: ' + str(i))\n",
    "        the_col = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print('a')\n",
    "                a = tf.constant(sess.run(next_element))\n",
    "                #print(a.eval())\n",
    "                the_col.append(sess.run(next_element))\n",
    "                #sess.run(a_col)\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('the_col is: ')\n",
    "                \n",
    "                print(list(the_col))\n",
    "                p_col = tf.stack(list(the_col))\n",
    "                print('p_col')\n",
    "                print(p_col)\n",
    "                print('the mean is: ')\n",
    "                print(sess.run(tf.reduce_mean(p_col)))\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the csv: 4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-288ba093bc1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m\"ex.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mselect_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Only parse last three columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[0mnext_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "# DEV\n",
    "\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get the numbers of columns in the csv:\n",
    "\n",
    "csv_in = open(\"ex.csv\", \"r\")                        # open the csv\n",
    "ncol = len(csv_in.readline().split(\",\"))            # read the first line and count the # of columns\n",
    "csv_in.close()                                      # close the csv\n",
    "print(\"Number of columns in the csv: \" + str(ncol)) # print the # of columns\n",
    "\n",
    "# Create a random column reading list:\n",
    "#col_list = list(range(ncol))\n",
    "#shuffle(col_list)\n",
    "\n",
    "\n",
    "#temp_col = \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    \n",
    "    dataset = tf.contrib.data.CsvDataset(\n",
    "        \"ex.csv\",\n",
    "        [tf.int32],\n",
    "        select_cols=[i]  # Only parse last three columns\n",
    "    )\n",
    "    next_element = dataset.make_one_shot_iterator().get_next()\n",
    "    print('Current column: ' + str(i))\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            #print(sess.run(next_element))\n",
    "            current_elem = sess.run(next_element)\n",
    "\n",
    "            temp_col.append(sess.run(next_element))\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "\n",
    "            print(temp_col)\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the csv: 4\n",
      "Current column: 3\n",
      "\n",
      "[4.0, 8.0, 12.0]\n",
      "[ 4.  8. 12.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([-1.2247448,  0.       ,  1.2247448], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m           return tf_session.TF_SessionRun_wrapper(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m       \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m     \u001b[0;31m# If a tensor handle that is fed to a device incompatible placeholder,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;31m# we move the tensor to the right device, generate a new tensor handle,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: IteratorGetNext_196 = IteratorGetNext[output_shapes=[[]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_196)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b7fa3d76dce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1134\u001b[0m                     \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                     \u001b[0mfeed_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m                     accept_options=False):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m     def _run_fn(session, feed_dict, fetch_list, target_list, options,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m           return tf_session.TF_SessionPRun_wrapper(session, handle, feed_dict,\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: IteratorGetNext_196 = IteratorGetNext[output_shapes=[[]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_196)]]\n\nCaused by op 'IteratorGetNext_196', defined at:\n  File \"/Users/admin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/admin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-70-b7fa3d76dce7>\", line 28, in <module>\n    next_element = dataset.make_one_shot_iterator().get_next()\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 373, in get_next\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1745, in iterator_get_next\n    r\"\"\"Creates a dataset that skips `count` elements from the `input_dataset`.\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    def get_operations(self):\n  File \"/Users/admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    Returns:\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: IteratorGetNext_196 = IteratorGetNext[output_shapes=[[]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_196)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m                         % (fetch, type(fetch), str(e)))\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3612\u001b[0m     \u001b[0mbe\u001b[0m \u001b[0mmodified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m \u001b[0mto\u001b[0m \u001b[0mchange\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3613\u001b[0;31m     \u001b[0;32mnot\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3701\u001b[0m         \u001b[0moriginal\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3702\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3703\u001b[0m     \u001b[0mYields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b7fa3d76dce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mnormalized_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mrun_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;31m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m     \u001b[0;31m# of a handle from a different device as an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0mfinal_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m                     (fetch, type(fetch)))\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m\"\"\"Fetch mapper for singleton tensors and ops.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    284\u001b[0m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[1;32m    285\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0m\u001b[1;32m    287\u001b[0m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[1;32m    288\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([-1.2247448,  0.       ,  1.2247448], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "# WORKING VERSION\n",
    "\n",
    "from random import shuffle\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "# Get the numbers of columns in the csv:\n",
    "\n",
    "csv_in = open(\"ex.csv\", \"r\")                        # open the csv\n",
    "ncol = len(csv_in.readline().split(\",\"))            # read the first line and count the # of columns\n",
    "csv_in.close()                                      # close the csv\n",
    "print(\"Number of columns in the csv: \" + str(ncol)) # print the # of columns\n",
    "\n",
    "# Create a random column reading list:\n",
    "col_list = list(range(ncol))\n",
    "shuffle(col_list)\n",
    "\n",
    "\n",
    "\n",
    "for i in col_list:\n",
    "    \n",
    "    dataset = tf.contrib.data.CsvDataset(\n",
    "        \"ex.csv\",\n",
    "        [tf.float32],\n",
    "        select_cols=[i]  # Only parse last three columns\n",
    "    )\n",
    "    \n",
    "    next_element = dataset.make_one_shot_iterator().get_next()\n",
    "    column = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        print('Current column: ' + str(i) + \"\\n\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                column.append(list(sess.run(next_element))[0])\n",
    "                \n",
    "                \n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                tc = tf.stack(column)\n",
    "                print(column)\n",
    "                print(sess.run(tc))\n",
    "                \n",
    "                mean, var = tf.nn.moments(tc, axes=[0])\n",
    "                normalized_col = tf.map_fn(lambda x: (x - mean)/tf.sqrt(var), tc)\n",
    "                stack = tf.stack(normalized_col)\n",
    "                print(sess.run(normalized_col.eval()))\n",
    "                print(stack.eval())\n",
    "                print(\"\\n\")\n",
    "                                          \n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the csv: 4\n",
      "Current column to be full pass: 0\n",
      "[1.0, 5.0, 9.0]\n",
      "Tensor(\"map_4/TensorArrayStack/TensorArrayGatherV3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      "\n",
      "Current column to be full pass: 2\n",
      "[3.0, 7.0, 11.0]\n",
      "Tensor(\"map_5/TensorArrayStack/TensorArrayGatherV3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      "\n",
      "Current column to be full pass: 3\n",
      "[4.0, 8.0, 12.0]\n",
      "Tensor(\"map_6/TensorArrayStack/TensorArrayGatherV3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      "\n",
      "Current column to be full pass: 1\n",
      "[2.0, 6.0, 10.0]\n",
      "Tensor(\"map_7/TensorArrayStack/TensorArrayGatherV3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WORKING VERSION\n",
    "\n",
    "\n",
    "\n",
    "# Get the numbers of columns in the csv:\n",
    "\n",
    "csv_in = open(\"ex.csv\", \"r\")                        # open the csv\n",
    "ncol = len(csv_in.readline().split(\",\"))            # read the first line and count the # of columns\n",
    "csv_in.close()                                      # close the csv\n",
    "print(\"Number of columns in the csv: \" + str(ncol)) # print the # of columns\n",
    "\n",
    "\n",
    "# Create random column order list (dataset) + iterator\n",
    "col_list = tf.data.Dataset.range(ncol).shuffle(buffer_size=ncol)\n",
    "col_next = col_list.make_one_shot_iterator().get_next()\n",
    "\n",
    "#def scale_zscore(vector):\n",
    "#    mean, var = tf.nn.moments(vector, axes=[0])\n",
    "#    normalized_col = tf.map_fn(lambda x: (x - mean)/tf.sqrt(var), vector)\n",
    "#    return normalized_col\n",
    "\n",
    "# Launch of graph\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    while True: # Loop on 'col_next', the queue of column iterator\n",
    "        try:\n",
    "            index = sess.run(col_next)\n",
    "            dataset = tf.contrib.data.CsvDataset( # Creates a dataset of the current csv column\n",
    "                        \"ex.csv\",\n",
    "                        [tf.float32],\n",
    "                        select_cols=[index]  # Only parse last three columns\n",
    "                    )\n",
    "            next_element = dataset.make_one_shot_iterator().get_next() # Creates an iterator\n",
    "            print('Current column to be full pass: ' + str(index))\n",
    "            current_col = []\n",
    "            while True: \n",
    "                try:\n",
    "                    current_col.append(sess.run(next_element)[0]) # Full pass\n",
    "                except tf.errors.OutOfRangeError: # End of full pass\n",
    "                    \n",
    "                    print(current_col)\n",
    "                    current_col = tf.convert_to_tensor([current_col])\n",
    "                    mean, var = tf.nn.moments(current_col, axes=[0])\n",
    "                    normalized_col = tf.reshape(tf.map_fn(lambda x: (x - mean)/tf.sqrt(var), current_col), [current])\n",
    "                    print(normalized_col)\n",
    "                    print('\\n')\n",
    "                    \n",
    "                    break\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
